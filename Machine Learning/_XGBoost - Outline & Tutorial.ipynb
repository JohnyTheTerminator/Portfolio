{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad667067",
   "metadata": {},
   "source": [
    "# STEP BY STEP TUTORIAL HOW TO IMPLEMENT XGBOOST ML MODEL\n",
    "# ●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385febe",
   "metadata": {},
   "source": [
    "# Part 1 \n",
    "\n",
    "# IMPORTING THE DATA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6e850",
   "metadata": {},
   "source": [
    "### Import data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc68e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.read_csv('filename.csv') # reading CSV file\n",
    "pd.read_excel('filename.xlsx') #reading excel file\n",
    "pd.read_json('filename.json') #reading json file\n",
    "pd.read_html('filename.html') #reading html file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31602486",
   "metadata": {},
   "source": [
    "### Import data from SQL Server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d9582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pypyodbc.Connection object at 0x000002428443BF40>\n"
     ]
    }
   ],
   "source": [
    "import pypyodbc as odbc\n",
    "\n",
    "DRIVER_NAME = 'SQL Server'\n",
    "SERVER_NAME = 'server name'\n",
    "DATABASE_NAME = 'Database name'\n",
    "\n",
    "connection_string = f\"\"\"\n",
    "    DRIVER={{{DRIVER_NAME}}};\n",
    "    SERVER={SERVER_NAME};\n",
    "    DATABASE={DATABASE_NAME};\n",
    "    Trusted_Connection=yes;\n",
    "\"\"\"   \n",
    "\n",
    "conn = odbc.connect(connection_string)\n",
    "print(conn)\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "query = 'SELECT * FROM [TableScheme].[Table]'\n",
    "df = pd.read_sql(query, odbc.connect(connection_string))\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e7f70",
   "metadata": {},
   "source": [
    "### Import data from URL File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('https://example.com/data.csv') #reads URL file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87babb30",
   "metadata": {},
   "source": [
    "# ●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937e221",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "# Data manipulation  & Data cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792416b",
   "metadata": {},
   "source": [
    "#### Number of rows and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82980b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape #shape, how many rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e773a7c5",
   "metadata": {},
   "source": [
    "#### Data Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea8ed86",
   "metadata": {},
   "source": [
    "#### Unique Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc45dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column name'].unique()\n",
    "\n",
    "# output: ([array of unique numbers]), dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a1fb4",
   "metadata": {},
   "source": [
    "#### Missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18faf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()   # Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fd16d",
   "metadata": {},
   "source": [
    "#### Column names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns  #To get the column names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d431e",
   "metadata": {},
   "source": [
    "#### Description of values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f099b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\n",
    "#OUTPUT:\n",
    "\n",
    "# count\n",
    "# mean\n",
    "# std\n",
    "# min\n",
    "# 25%\n",
    "# 50%\n",
    "# 75%\n",
    "# max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe310d4",
   "metadata": {},
   "source": [
    "#### Check for duplicated values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1931738",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    num_duplicates = df.duplicated(subset=col).sum()                        #what columns do have duplciates in them\n",
    "    print(f\"Column '{col}' has {num_duplicates} duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7197d66",
   "metadata": {},
   "source": [
    "#### Sorting the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a7921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"Amount\", ascending=False).head() #single column, in this case Amount\n",
    "df.sort_values(by=[\"Churn\", \"Total day charge\"], ascending=[True, False]).head()  #multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff3ec5",
   "metadata": {},
   "source": [
    "#### replacing values in dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column name'].replace('vale to be replaced', 'replace value', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bce53f",
   "metadata": {},
   "source": [
    "#### Drop the column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3867a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 1 column\n",
    "df.drop('column name', axis=1, inplace=True)\n",
    "\n",
    "# drop mutliple columns\n",
    "columns_to_drop = ['column_name_1', 'column_name_2']\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c80d47",
   "metadata": {},
   "source": [
    "#### Rename columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfcf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'actual column name': 'new column name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f41bd",
   "metadata": {},
   "source": [
    "# ●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1318a2",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a9caa",
   "metadata": {},
   "source": [
    "# Label encoding \n",
    "\n",
    "\n",
    "Machine learning models are able to process only nuemrical data, that emans that you need to transform the data taht are strings into numerical values so the model then can learn and predict.\n",
    "\n",
    "In this case we encode the columns and print out also their previous values so we can see alter on how the data was transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09196291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_columns = ['categorical_column1', 'categorical_column2', 'categorical_column3'] #Just examples, replace with the columns you need to encode\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Create a dictionary to store the encoded labels\n",
    "encoded_labels = {}\n",
    "\n",
    "# Perform label encoding for each categorical column\n",
    "for column in categorical_columns:\n",
    "    encoded_labels[column] = dict(zip(label_encoder.fit(df[column]).classes_, label_encoder.transform(label_encoder.fit(df[column]).classes_)))\n",
    "    df[column] = label_encoder.transform(df[column])\n",
    "\n",
    "\n",
    "# Display the original values and their corresponding encoded labels for each categorical column\n",
    "for column, encoding_map in encoded_labels.items():\n",
    "    print(f\"Original values for {column}: {encoding_map}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac62b9",
   "metadata": {},
   "source": [
    "# ●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0cc54",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "\n",
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06456c8b",
   "metadata": {},
   "source": [
    "### Defining the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b51a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# X should contain all the features that you want to use as input to your machine learning model for prediction\n",
    "X = df.drop(columns=['Column names'])\n",
    "# Y is a Series containing the target variable (dependent variable) that you want to predict.\n",
    "y = df['column name']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914e06d",
   "metadata": {},
   "source": [
    "### Splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a9dfe0",
   "metadata": {},
   "source": [
    "###  Standard Scaling - NOT MANDATORY!! \n",
    "\n",
    "The purpose of scaling the features using StandardScaler is to ensure that all features have the same scale (mean = 0 and standard deviation = 1). This is particularly important for algorithms that are sensitive to the scale of the features, such as gradient descent-based algorithms (e.g., linear regression, logistic regression) and distance-based algorithms (e.g., k-nearest neighbors). Normalizing the features can improve the performance and convergence of these algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d319ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad77c7",
   "metadata": {},
   "source": [
    "# ●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○● "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba897e",
   "metadata": {},
   "source": [
    "# Part 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8780c1",
   "metadata": {},
   "source": [
    "# Machine Learning models in XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde4f26",
   "metadata": {},
   "source": [
    "## Classification Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76905bc8",
   "metadata": {},
   "source": [
    "### Binary Classification: \n",
    "\n",
    "Target Variable: The dataset should have a binary target variable with two classes (e.g., 0 and 1, 'Yes' and 'No').\n",
    "\n",
    "Class Balance: Ensure that the dataset has a balanced distribution of the two classes to prevent bias towards the majority class.\n",
    "\n",
    "Evaluation Metric: Common evaluation metrics include accuracy, precision, recall, F1-score, and ROC-AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06304030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier() #(binary classification using decision trees)\n",
    "\n",
    "model = XGBRFClassifier() #(binary classification using random forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8f0f7",
   "metadata": {},
   "source": [
    "### Multiclass Classification: \n",
    "\n",
    "Target Variable: The dataset should have a target variable with more than two classes (e.g., 3 or more).\n",
    "\n",
    "Sufficient Samples: Make sure there are enough samples for each class to avoid overfitting and under-represented classes.\n",
    "\n",
    "Data Format: The target variable should be categorical with integer labels representing different classes.\n",
    "\n",
    "Evaluation Metric: Common evaluation metrics include accuracy, macro/micro F1-score, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d722888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(objective='multi:softmax') #with objective='multi:softmax' (multiclass classification using decision trees)\n",
    "\n",
    "model = XGBRFClassifier(objective='multi:softmax') #with objective='multi:softmax' (multiclass classification using random forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92c520",
   "metadata": {},
   "source": [
    "### Probability Estimation:\n",
    "    \n",
    "Similar to binary classification, but the output will be probabilities of the positive class (e.g., likelihood of 'Yes').\n",
    "\n",
    "Probability Threshold: You can set a probability threshold to convert probabilities into class predictions (e.g., 0.5 for binary classification).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(objective='binary:logistic') #with objective='binary:logistic' (binary classification with probability outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab402664",
   "metadata": {},
   "source": [
    "## Regression Models:\n",
    "\n",
    "Target Variable: The dataset should have a continuous (numeric) target variable representing the value to be predicted.\n",
    "\n",
    "Data Format: The features should be numerical and contribute to predicting the target variable.\n",
    "\n",
    "Evaluation Metric: Common evaluation metrics include mean squared error (MSE), mean absolute error (MAE), and R-squared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor() #(regression using decision trees)\n",
    "\n",
    "model = XGBRFRegressor() #(regression using random forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a5e84",
   "metadata": {},
   "source": [
    "## Ranking Models:\n",
    "\n",
    "Dataset Format: Suitable for learning-to-rank problems, where instances are ranked based on relevance or preference.\n",
    "\n",
    "Features: The dataset may include features representing user-item interactions, user preferences, and item attributes.\n",
    "\n",
    "Evaluation Metric: Ranking metrics like NDCG (Normalized Discounted Cumulative Gain) and MAP (Mean Average Precision) are commonly used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRanker\n",
    "\n",
    "model = XGBRanker() #(ranker for learning-to-rank problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f97eab",
   "metadata": {},
   "source": [
    "## Anomaly Detection Models:\n",
    "\n",
    "Dataset Format: The dataset should be labeled with binary classes (e.g., normal and anomaly).\n",
    "\n",
    "Class Imbalance: Anomaly detection often deals with class imbalance, where anomalies are a small fraction of the total samples.\n",
    "\n",
    "Evaluation Metric: Metrics like precision, recall, and F1-score are used to assess anomaly detection performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = xgb.XGBClassifier(objective=anomaly_objective) #with custom objective function (anomaly detection with one-class classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010266c",
   "metadata": {},
   "source": [
    "## Time Series Forecasting Models:\n",
    "\n",
    "Dataset Format: The dataset should be time-ordered, with the target variable being the variable to forecast at a future time.\n",
    "\n",
    "Time-related Features: Additional time-related features like lags or time-based statistics can be useful for time series modeling.\n",
    "\n",
    "Evaluation Metric: Common evaluation metrics include mean absolute error (MAE), mean squared error (MSE), and root mean squared error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor() #with custom features (time series forecasting with lag features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83031844",
   "metadata": {},
   "source": [
    "## Ranking and Recommendation Models:\n",
    "\n",
    "Dataset Format: Suitable for personalized ranking or recommendation, often involving implicit or explicit feedback.\n",
    "\n",
    "Evaluation Metric: Ranking and recommendation models typically use metrics like NDCG, MAP, and AUC to evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c8b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRanker\n",
    "\n",
    "model = XGBRanker()\n",
    "\n",
    "model = XGBClassifier() #with custom objective (for personalized recommendation systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d101ec",
   "metadata": {},
   "source": [
    "# ●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea67ec",
   "metadata": {},
   "source": [
    "# Part 6\n",
    "\n",
    "# Parametrization\n",
    "\n",
    "param_grid: It's a dictionary that defines the hyperparameter grid to search over during the grid search. Hyperparameters are model parameters that are set before training and can significantly impact the model's performance. In this case, the grid specifies the values to try for two hyperparameters: n_estimators (number of boosting rounds) and learning_rate (step size shrinkage).\n",
    "\n",
    "GridSearchCV: It's a class from scikit-learn used for hyperparameter tuning using grid search. It performs an exhaustive search over the hyperparameter grid specified in param_grid. For each combination of hyperparameters, it uses cross-validation (specified by cv) to evaluate the model's performance.\n",
    "\n",
    "cv: It's the number of cross-validation folds used during grid search. In this case, cv=10, so it performs 10-fold cross-validation, meaning it splits the data into 10 subsets, trains the model on 9 of them, and validates on the remaining one.\n",
    "\n",
    "scoring: It's the evaluation metric used to compare different hyperparameter combinations. In this case, scoring='neg_mean_squared_error', which means it will use the negative mean squared error (MSE) as the evaluation metric. By default, scikit-learn optimizes for higher values of the scoring metric, so using negative MSE allows it to minimize the mean squared error.\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train): It performs the grid search with cross-validation using the training data (X_train_scaled and y_train). The best hyperparameters are determined based on the results of the cross-validation.\n",
    "\n",
    "grid_search.best_params_: After the grid search is completed, this attribute gives the best hyperparameters found during the search.\n",
    "\n",
    "grid_search.best_estimator_: It provides the best model obtained with the best hyperparameters found during grid search.\n",
    "\n",
    "best_model.fit(X_train_scaled, y_train): It trains the best model on the entire training set using the best hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e499f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Define the hyperparameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0f998e",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "#### n_estimators: Number of boosting rounds (trees).\n",
    "\n",
    "Typical Range: 50 to 1000 or more.\n",
    "\n",
    "Higher values can improve the performance of the model but may increase the training time.\n",
    "\n",
    "\n",
    "#### learning_rate: Step size shrinkage used to prevent overfitting.\n",
    "\n",
    "Typical Range: 0.01 to 0.3 or lower.\n",
    "\n",
    "Lower values require more boosting rounds (higher n_estimators) to achieve good performance.\n",
    "\n",
    "\n",
    "#### max_depth: Maximum depth of the individual trees.\n",
    "\n",
    "Typical Range: 3 to 10 or more.\n",
    "\n",
    "Higher values can lead to more complex models, but be cautious of overfitting.\n",
    "\n",
    "\n",
    "#### subsample: Fraction of samples used for fitting the individual trees.\n",
    "\n",
    "Typical Range: 0.5 to 1.0.\n",
    "\n",
    "Values less than 1.0 introduce stochasticity, which can help reduce overfitting.\n",
    "\n",
    "\n",
    "#### colsample_bytree: Fraction of features used for fitting the individual trees.\n",
    "\n",
    "Typical Range: 0.5 to 1.0.\n",
    "\n",
    "Values less than 1.0 introduce stochasticity, which can help reduce overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d6e34",
   "metadata": {},
   "source": [
    "# ●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c0abd",
   "metadata": {},
   "source": [
    "# Part 7\n",
    "\n",
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fd44d",
   "metadata": {},
   "source": [
    "### importance scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7cd113",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_scores = best_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate feature names with their importance scores\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importance_scores})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualize the feature importance scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8475a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ff471",
   "metadata": {},
   "source": [
    "### Evaluating\n",
    "\n",
    "#### R-squared (R2) Score: \n",
    "It measures the proportion of the variance in the dependent variable (target) that is predictable from the independent variables (features). It provides an indication of how well the model fits the data.\n",
    "\n",
    "#### Mean Absolute Error (MAE):\n",
    "It calculates the absolute difference between the actual and predicted values and then takes the average of those differences.\n",
    "\n",
    "#### Root Mean Squared Error (RMSE):\n",
    "It is the square root of the MSE and provides a more interpretable measure since it is in the same unit as the target variable.\n",
    "\n",
    "#### Mean Squared Logarithmic Error (MSLE): \n",
    "It calculates the mean squared logarithmic difference between the actual and predicted values. It is useful when the target variable has a wide range of values.\n",
    "\n",
    "#### Explained Variance Score:\n",
    "It measures the proportion of variance in the target variable that the model explains. It is another indicator of how well the model fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a610db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score, mean_squared_log_error\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# Calculate the R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "# Calculate the mean absolute error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "# Calculate the root mean squared error\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "# Calculate the mean squared logarithmic error\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "# Calculate the explained variance score\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"Mean Squared Logarithmic Error: {msle}\")\n",
    "print(f\"Explained Variance Score: {evs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a595ecaf",
   "metadata": {},
   "source": [
    "# ●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○●○● "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed0163",
   "metadata": {},
   "source": [
    "# Part 8\n",
    "\n",
    "# Saving & loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db59141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Assuming you have already trained your model and it is stored in the 'model' variable (in our case best_model)\n",
    "# Save the model to a file\n",
    "best_model.save_model('xgboost_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model('xgboost_model.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
